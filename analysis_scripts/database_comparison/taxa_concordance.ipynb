{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f3d6d1",
   "metadata": {},
   "source": [
    "## MetaPhlAn4 (vJun23) and Kraken2Uniq Taxa Concordance \n",
    "\n",
    "### Quantify the overlap between taxa based on NCBI ID's between the reference databases used by MetaPhlAn4 database vJun23 and custom Kraken2Uniq database, and concordance between the resulting taxa identified in ILO dataset\n",
    "\n",
    "#### Author: Sarah Bald, Date: May 13, 2024\n",
    "#### Edited: Sarah Bald, Date: November 12, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01bf0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import bz2\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e21bc",
   "metadata": {},
   "source": [
    "### Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a2792d-875a-4e28-87d5-8d96278d4051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source data paths, only change these when things get updated\n",
    "\n",
    "#metaphlan ilo data - source listed and csv version produced from script save_rds_as_csv.R\n",
    "mph_ilo_source_file = '/restricted/projectnb/uh2-sebas/data/metagenomics/ILO_combined_cohort/processed_data/data_library/metaphlan4_renorm_ILO_phyloseq.09.30.2024.rds'\n",
    "mph_ilo_file = '/restricted/projectnb/uh2-sebas/analysis/metagenomics/taxa_concordance/metaphlan4_renorm_ILO_phyloseq.09.30.2024.csv'\n",
    "\n",
    "#metaphlan han data\n",
    "mph_xu_source_file = '/restricted/projectnb/uh2-sebas/data/metagenomics/external_cohorts/Han_Chinese_Centenarian/processed_data/data_library/metaphlan4_renorm_chinese_phyloseq.10.23.2024.rds'\n",
    "mph_xu_file = '/restricted/projectnb/uh2-sebas/analysis/metagenomics/taxa_concordance/metaphlan4_renorm_xu_phyloseq.10.23.2024.csv'\n",
    "\n",
    "#metaphlan vJun23 database\n",
    "mph_db_file = '/restricted/projectnb/uh2-sebas/analysis/metagenomics/taxa_concordance/mpa_vJun23_CHOCOPhlAnSGB_202403.pkl'\n",
    "\n",
    "#bracken ilo data - source listed and csv version produced from script save_rds_as_csv.R\n",
    "bracken_ilo_source_file = '/restricted/projectnb/uh2-sebas/data/metagenomics/ILO_combined_cohort/processed_data/data_library/bracken_renorm_ILO_phyloseq.R1.K3.10.09.2024.rds'\n",
    "bracken_ilo_file = '/restricted/projectnb/uh2-sebas/analysis/metagenomics/taxa_concordance/bracken_renorm_ILO_phyloseq.R1.K3.10.09.2024.csv'\n",
    "\n",
    "#bracken han data\n",
    "bracken_xu_source_file = '/restricted/projectnb/uh2-sebas/data/metagenomics/external_cohorts/Han_Chinese_Centenarian/processed_data/data_library/bracken_renorm_chinese_phyloseq.R1.K3.10.22.2024.rds'\n",
    "bracken_xu_file = '/restricted/projectnb/uh2-sebas/analysis/metagenomics/taxa_concordance/bracken_renorm_xu_phyloseq.R1.K3.10.22.2024.csv'\n",
    "\n",
    "#kraken2 database inspect file\n",
    "k2_db_file = '/restricted/projectnb/uh2-sebas/data/metagenomics/Kraken2-DB/Kraken2Uniq-DB-09222023/inspect_db.sh.o2952984'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e009fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD DATA LOADING CODE\n",
    "\n",
    "#load metaphlan merged relative abundance tables for ILO and Han Chinese cohort\n",
    "#table from phyloseq object\n",
    "#mph4_ilo = pd.read_csv('/restricted/projectnb/uh2-sebas/analysis/metagenomics/taxa_concordance/ilo_mph4_04022024.csv')\n",
    "#mph4_han = pd.read_table('/restricted/projectnb/uh2-sebas/analysis/humann_han_chinese/humann3.9/merged_out/raw_merged/merged_metaphlan4_bugs_list.tsv', skiprows=1)\n",
    "\n",
    "#load kraken2uniq merged relative abundance tables for ILO and Han Chinese cohort\n",
    "#k2u_ilo = pd.read_csv('/restricted/projectnb/uh2-sebas/analysis/metagenomics/taxa_concordance/bracken_count_ILO_phyloseq.filtered.06.11.2024.csv')\n",
    "#k2u_han = pd.read_csv('/restricted/projectnb/uh2-sebas/analysis/metagenomics/taxa_concordance/bracken_count_chinese_phyloseq.filtered.05.14.2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf8024a",
   "metadata": {},
   "source": [
    "### Turn raw data into consistent dictionary structure for each data source\n",
    "#### Nested dictionary structured with taxonomy levels as first layer of keys and ID's as second layer with names as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cdc0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping length of id and name to correct taxonomic level\n",
    "level_name_dict = {1: 'Kingdom', 2: 'Phylum', 3:\"Class\", 4:'Order', 5:'Family', 6:'Genus', 7:'Species'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e3e3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20789"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#process metaphlan database into dictionary of taxa ID's/names\n",
    "mph_db_dict = {'Kingdom':{}, 'Phylum':{}, 'Class':{}, 'Order':{}, 'Family':{}, 'Genus':{}, 'Species':{}}\n",
    "mph_db = pickle.load(bz2.open(mph_db_file,'rb'))\n",
    "mph_db.pop('markers')\n",
    "#loop through all species genome bins first\n",
    "for name in mph_db['taxonomy'].keys():\n",
    "    ncbi = mph_db['taxonomy'][name][0]\n",
    "    # check each taxonomic level\n",
    "    for level in range(7):\n",
    "        sub_name = '|'.join(name.split('|')[:level+1])\n",
    "        sub_ncbi = '|'.join(ncbi.split('|')[:level+1])\n",
    "        #exclude taxa with incomplete classification\n",
    "        if sub_ncbi.endswith('|') or '||' in sub_ncbi:\n",
    "            break\n",
    "        #add to dictionary\n",
    "        if sub_ncbi not in mph_db_dict[level_name_dict[level+1]]:\n",
    "            mph_db_dict[level_name_dict[level+1]][sub_ncbi] = sub_name\n",
    "\n",
    "\n",
    "#add names/ID's for SGB's that collapse multiple species\n",
    "#additional_taxa = list(mph4_db['merged_taxon'].values())\n",
    "#add_taxa = [item for sublist in additional_taxa for item in sublist]\n",
    "#for taxa_pair in add_taxa:\n",
    "#    ncbi = taxa_pair[1]\n",
    "#    name = taxa_pair[0]\n",
    "    # check each taxonomic level\n",
    "#    for level in range(7):\n",
    "#        sub_name = '|'.join(name.split('|')[:level+1])\n",
    "#        sub_ncbi = '|'.join(ncbi.split('|')[:level+1])\n",
    "        #exclude taxa with incomplete classification\n",
    "#        if sub_ncbi.endswith('|') or '||' in sub_ncbi:\n",
    "#            break\n",
    "        #add to dictionary\n",
    "#        if sub_ncbi not in mph4_db_dict[level_name_dict[level+1]]:\n",
    "#            mph4_db_dict[level_name_dict[level+1]][sub_ncbi] = sub_name\n",
    "\n",
    "\n",
    "len(mph_db_dict['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82477b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23127"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#process kraken database into dictionary of taxa ID's/names\n",
    "kraken_db_dict = {'Kingdom':{}, 'Phylum':{}, 'Class':{}, 'Order':{}, 'Family':{}, 'Genus':{}, 'Species':{}}\n",
    "kraken2uniq_db = pd.read_table(k2_db_file ,header=None, names=['percent_of_database_minimizers_in_clade', 'minimizers_in_clade', 'taxa_minimizers', 'taxa_level', 'taxa_id', 'taxa_name'] )\n",
    "kraken_db_name_id = kraken2uniq_db[['taxa_level', 'taxa_id', 'taxa_name']].copy()\n",
    "\n",
    "#add each new taxa represented to a large list, along with id\n",
    "taxa_id_pairs = []\n",
    "level_map = {'D':0, 'P':1, 'C':2, 'O':3, 'F':4, 'G':5, 'S':6}\n",
    "taxonomy_id = ['','','','','','','']\n",
    "taxonomy_name = ['','','','','','','']\n",
    "for i in range(len(kraken_db_name_id)):\n",
    "    level = kraken_db_name_id.loc[i,'taxa_level']\n",
    "    if level == 'D':\n",
    "        text_level = 'K'\n",
    "    else:\n",
    "        text_level = level\n",
    "    num = str(kraken_db_name_id.loc[i,'taxa_id'])\n",
    "    name = str(text_level.lower() + '__' + kraken_db_name_id.loc[i,'taxa_name'].strip())\n",
    "    if level in level_map.keys():\n",
    "        taxonomy_name[level_map[level]] = name\n",
    "        taxonomy_id[level_map[level]] = num\n",
    "        \n",
    "        #wash out taxonomy and id labels after this newly updated one\n",
    "        j = level_map[level]\n",
    "        for m in range(len(taxonomy_name)):\n",
    "            if m > j:\n",
    "                taxonomy_name[m] = ''\n",
    "                taxonomy_id[m] = ''\n",
    "        \n",
    "        #save completed taxa as a id/name pair\n",
    "        taxa_id_pairs.append(('|'.join(taxonomy_name), '|'.join(taxonomy_id)))\n",
    "\n",
    "for pair in taxa_id_pairs:\n",
    "    name = pair[0]\n",
    "    ncbi = pair[1]\n",
    "    # check each taxonomic level\n",
    "    for level in range(len(ncbi.split('|'))):\n",
    "        sub_name = '|'.join(name.split('|')[:level+1])\n",
    "        sub_ncbi = '|'.join(ncbi.split('|')[:level+1])\n",
    "        #exclude taxa with incomplete classification\n",
    "        if sub_ncbi.endswith('|') or '||' in sub_ncbi:\n",
    "            break\n",
    "        #add to dictionary\n",
    "        if sub_ncbi not in kraken_db_dict[level_name_dict[level+1]]:\n",
    "            kraken_db_dict[level_name_dict[level+1]][sub_ncbi] = sub_name\n",
    "len(kraken_db_dict['Species'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e023ce-cb6c-4f23-a2db-3b6679c737f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_taxa_csv_output(file, db_dict):\n",
    "    data_dict = {'Kingdom':{}, 'Phylum':{}, 'Class':{}, 'Order':{}, 'Family':{}, 'Genus':{}, 'Species':{}}\n",
    "\n",
    "    #read in source data, concatenate name and save species ID's\n",
    "    df = pd.read_csv(file, index_col=0)\n",
    "    names = ['|'.join(df.iloc[i].values[:]) for i in range(len(df))]\n",
    "    sp_id = [str(i) for i in df.index]\n",
    "\n",
    "    #match species ID with database entry to get full taxonomy ID\n",
    "    ncbi_ids = []\n",
    "    db_sp = list(db_dict['Species'].keys())\n",
    "    for sp in sp_id:\n",
    "        found = False\n",
    "        for s in db_sp:\n",
    "            if s.split('|')[-1] == sp:\n",
    "                ncbi_ids.append(s)\n",
    "                found = True\n",
    "        if not found:\n",
    "            print('Species not found with ID: ' + sp)\n",
    "            ncbi_ids.append('')\n",
    "\n",
    "    for name, ncbi in zip(names, ncbi_ids):\n",
    "        # check each taxonomic level\n",
    "        for level in range(len(ncbi.split('|'))):\n",
    "            sub_name = '|'.join(name.split('|')[:level+1])\n",
    "            sub_ncbi = '|'.join(ncbi.split('|')[:level+1])\n",
    "            #exclude taxa with incomplete classification\n",
    "            if sub_ncbi.endswith('|') or '||' in sub_ncbi:\n",
    "                break\n",
    "            #add to dictionary\n",
    "            if sub_ncbi not in data_dict[level_name_dict[level+1]]:\n",
    "                data_dict[level_name_dict[level+1]][sub_ncbi] = sub_name\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db0b391-9b73-48a8-adac-74cf7781436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mph_ilo_dict = process_taxa_csv_output(mph_ilo_file, mph_db_dict)\n",
    "bracken_ilo_dict = process_taxa_csv_output(bracken_ilo_file, kraken_db_dict)\n",
    "mph_xu_dict = process_taxa_csv_output(mph_xu_file, mph_db_dict)\n",
    "bracken_xu_dict = process_taxa_csv_output(bracken_xu_file, kraken_db_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56cc413f-0df3-4010-a193-264a6422e19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787\n",
      "1044\n",
      "898\n",
      "1504\n"
     ]
    }
   ],
   "source": [
    "print(len(mph_ilo_dict['Species']))\n",
    "print(len(bracken_ilo_dict['Species']))\n",
    "print(len(mph_xu_dict['Species']))\n",
    "print(len(bracken_xu_dict['Species']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae13d446",
   "metadata": {},
   "source": [
    "### Quality Control\n",
    "#### Check that Metaphlan taxa are in Metaphlan Database, same for Kraken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3694ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_matching_keys(dict1, dict2):\n",
    "    missing_taxa = {}  # Dictionary to store missing taxa for each level\n",
    "    all_taxa_match = True  # Variable to track if all taxa IDs match\n",
    "    \n",
    "    # Iterate over the keys of the first dictionary\n",
    "    for level, taxa_dict in dict1.items():\n",
    "        # Check if the level exists in the second dictionary\n",
    "        if level in dict2:\n",
    "            # Get the taxa IDs from the first dictionary\n",
    "            dict1_taxa_ids = set(taxa_dict.keys())\n",
    "            # Get the taxa IDs from the second dictionary\n",
    "            dict2_taxa_ids = set(dict2[level].keys())\n",
    "            # Check if all taxa IDs from the first dictionary exist in the second dictionary\n",
    "            if not dict1_taxa_ids.issubset(dict2_taxa_ids):\n",
    "                # Update all_taxa_match to False if any taxa IDs are missing\n",
    "                all_taxa_match = False\n",
    "                # Find the missing taxa\n",
    "                missing_taxa[level] = dict1_taxa_ids.difference(dict2_taxa_ids)\n",
    "        else:\n",
    "            # Update all_taxa_match to False if the level is missing in the second dictionary\n",
    "            all_taxa_match = False\n",
    "            # Store all taxa IDs as missing if the level is missing in the second dictionary\n",
    "            missing_taxa[level] = set(taxa_dict.keys())\n",
    "    \n",
    "    return all_taxa_match, missing_taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9814e035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_taxa_match, missing_taxa = check_matching_keys(mph_xu_dict, mph_db_dict)\n",
    "all_taxa_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecdede04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_taxa_match, missing_taxa = check_matching_keys(bracken_xu_dict, kraken_db_dict)\n",
    "all_taxa_match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45601a5b",
   "metadata": {},
   "source": [
    "### Taxa Overlap\n",
    "#### Between Kraken and Metaphlan databases, and cohorts at each taxonomic level. Organize into dictionaries grouping by taxa in common and unique to a cohort/profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e23d264-9c4c-48fd-b0a5-879c95a77a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def taxa_overlap(dict1_name, dict2_name, dict1, dict2, verbose=True):\n",
    "    categorized_taxa = {}  # Nested dictionary to store categorized taxa\n",
    "    taxonomic_levels = ['Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']\n",
    "    num_inconsistencies = 0\n",
    "    mph_mismatch = []\n",
    "    krk_mismatch = []\n",
    "    \n",
    "    # Iterate over the keys of the dictionaries\n",
    "    for level, taxa_dict1 in dict1.items():\n",
    "        # Initialize dictionaries to store categorized taxa at each level\n",
    "        categorized_taxa[level] = {'Overlap': {}, dict1_name: {}, dict2_name: {}}\n",
    "        level_index = taxonomic_levels.index(level)\n",
    "        \n",
    "        # Get taxa IDs from both dictionaries at the specified level\n",
    "        taxa_ids_dict1 = set(taxa_id.split('|')[level_index] for taxa_id in taxa_dict1.keys()) \n",
    "        \n",
    "        if level in dict2:\n",
    "            taxa_ids_dict2 = set(taxa_id.split('|')[level_index] for taxa_id in dict2[level].keys())  \n",
    "        else:\n",
    "            taxa_ids_dict2 = set()\n",
    "        \n",
    "        # Find overlapping taxa IDs\n",
    "        overlapping_taxa_ids = taxa_ids_dict1.intersection(taxa_ids_dict2)  \n",
    "\n",
    "        #Check ID mismatch at higher levels of classification -- still currently counted as a match at current level\n",
    "        for match in overlapping_taxa_ids:  \n",
    "            for taxa_id1 in taxa_dict1:\n",
    "                if taxa_id1.split('|')[level_index] == match:\n",
    "                    for taxa_id2 in dict2[level]:\n",
    "                        if taxa_id2.split('|')[level_index] == match:\n",
    "                            if not taxa_id1 == taxa_id2:\n",
    "                                num_inconsistencies+=1\n",
    "                                if verbose:\n",
    "                                    print(\"\\n WARNING: MISMATCH AT HIGHER LEVEL \\nMetaphlan ID: \"+str(taxa_id1)+\"\\nMetaphlan Name: \"+str(dict1[level][taxa_id1])+\"\\nBracken ID: \"+str(taxa_id2)+\"\\nBracken Name: \"+str(dict2[level][taxa_id2]) )\n",
    "                                    #current_name, current_taxid = get_current_ncbi_info(match)\n",
    "                                    #print(\"Current NCBI name: \"+current_name+\"\\nCurrent NCBI ID: \" +current_taxid)\n",
    "\n",
    "                                    \n",
    "                            # Store overlapping taxa\n",
    "                            categorized_taxa[level]['Overlap'][taxa_id1] = dict1[level][taxa_id1]\n",
    "        \n",
    "        # Find taxa IDs only in dictionary1\n",
    "        taxa_ids_dict1_only = taxa_ids_dict1.difference(taxa_ids_dict2)\n",
    "        for match in taxa_ids_dict1_only:  \n",
    "            for taxa_id in taxa_dict1:\n",
    "                if taxa_id.split('|')[level_index] == match:  \n",
    "                    # Store taxa only in dictionary1\n",
    "                    categorized_taxa[level][dict1_name][taxa_id] = taxa_dict1[taxa_id]\n",
    "\n",
    "        # Find taxa IDs only in dictionary2\n",
    "        taxa_ids_dict2_only = taxa_ids_dict2.difference(taxa_ids_dict1)\n",
    "        if level in dict2:\n",
    "            for match in taxa_ids_dict2_only:  \n",
    "                for taxa_id in dict2[level]:\n",
    "                    if taxa_id.split('|')[level_index] == match: \n",
    "                        # Store taxa only in dictionary2\n",
    "                        categorized_taxa[level][dict2_name][taxa_id] = dict2[level][taxa_id]\n",
    "        else:\n",
    "            categorized_taxa[level][dict2_name] = {}\n",
    "\n",
    "    return categorized_taxa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25f91bd8-fab9-4f80-a7d9-56b268a210c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_unique_taxa(mph_taxa, bracken_taxa, mph_db, kraken_db):\n",
    "    \n",
    "    #get overlap between sample data with both profilers\n",
    "    overlap = taxa_overlap('mph', 'kraken', mph_taxa, bracken_taxa, verbose=False)\n",
    "\n",
    "    #get overlap between sample data and opposite profiler database\n",
    "    mph_kraken_db_overlap = taxa_overlap('mph', 'kraken_db', mph_taxa, kraken_db, verbose=False)\n",
    "    bracken_mph_db_overlap = taxa_overlap('mph_db', 'bracken', mph_db, bracken_taxa, verbose=False)\n",
    "\n",
    "    #set up dictionary for results\n",
    "    unique_taxa_overlap = {}\n",
    "    taxonomic_levels = ['Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']\n",
    "    \n",
    "    for level in taxonomic_levels:\n",
    "\n",
    "        #for each level compare ilo_overlap unique lists, and separate the ones in db_overlap overlap lists \n",
    "        unique_taxa_overlap[level] = {\"mph_only_not_overlap\" : {},\"mph_only_overlap\" : {},\n",
    "                           \"kraken_only_not_overlap\" : {}, \"kraken_only_overlap\": {}}\n",
    "\n",
    "        # Compare mph_only of dict1 with overlap of dict2\n",
    "        for id_, name in overlap[level][\"mph\"].items():\n",
    "            if id_ in mph_kraken_db_overlap[level][\"Overlap\"]:\n",
    "                unique_taxa_overlap[level][\"mph_only_overlap\"][id_] = name\n",
    "            else:\n",
    "                unique_taxa_overlap[level][\"mph_only_not_overlap\"][id_] = name\n",
    "\n",
    "        # Compare kraken_only of dict1 with overlap of dict2\n",
    "        for id_, name in overlap[level][\"kraken\"].items():\n",
    "            if id_ in bracken_mph_db_overlap[level][\"Overlap\"]:\n",
    "                unique_taxa_overlap[level][\"kraken_only_overlap\"][id_] = name\n",
    "            else:\n",
    "                unique_taxa_overlap[level][\"kraken_only_not_overlap\"][id_] = name\n",
    "\n",
    "    return unique_taxa_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47788065-88ed-4b2d-a1e5-7958f5a7e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_ncbi_info(taxa_id):\n",
    "    '''From a ncbi ID at any taxonomic level, report back the name of all higher levels up to the level provided as well as the most up to date ncbi ID'''\n",
    "\n",
    "    os.system(f\"datasets summary taxonomy taxon {taxa_id} --as-json-lines | dataformat tsv taxonomy --template tax-summary > temp.tsv\")\n",
    "    raw_taxa_df = pd.read_table('temp.tsv')\n",
    "\n",
    "    taxa_df = raw_taxa_df[['Superkingdom name','Superkingdom taxid', 'Phylum name', 'Phylum taxid', 'Class name', 'Class taxid','Order name', 'Order taxid',\n",
    "                       'Family name', 'Family taxid', 'Genus name', 'Genus taxid', 'Species name', 'Species taxid']]\n",
    "    print(raw_taxa_df.loc[0,:])\n",
    "\n",
    "    #shorten df to taxonomic level of input taxid\n",
    "    taxa_df = taxa_df.loc[0,:][:(taxa_df.loc[0,:]).last_valid_index()]\n",
    "\n",
    "    name_df = taxa_df.filter(like='name')\n",
    "    taxid_df = taxa_df.filter(like='taxid')\n",
    "    \n",
    "    taxid = '|'.join(taxid_df.fillna('').astype(str))\n",
    "    name = '|'.join(name_df.fillna('').astype(str))\n",
    "    \n",
    "    return name, taxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b03c8ea-3dd8-4c18-8be3-f27be421caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "xu_overlap = taxa_overlap('mph', 'kraken', mph_xu_dict, bracken_xu_dict, verbose=False)\n",
    "ilo_overlap = taxa_overlap('mph', 'kraken', mph_ilo_dict, bracken_ilo_dict, verbose=False)\n",
    "db_overlap = taxa_overlap('mph', 'kraken', mph_db_dict, kraken_db_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d15086d9-42a7-4c81-add6-31c5bb0f231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xu_unique_cat = categorize_unique_taxa(mph_xu_dict, bracken_xu_dict, mph_db_dict, kraken_db_dict)\n",
    "ilo_unique_cat = categorize_unique_taxa(mph_ilo_dict, bracken_ilo_dict, mph_db_dict, kraken_db_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1552557-975e-40a4-ad3d-61bb166778e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kraken_overlap = taxa_overlap('ilo', 'xu', bracken_ilo_dict, bracken_xu_dict, verbose=False)\n",
    "mph_overlap = taxa_overlap('ilo', 'xu', mph_ilo_dict, mph_xu_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a5cdf-5351-46c5-a861-5aa684d59160",
   "metadata": {},
   "source": [
    "## Summarize Overlap Taxa Counts\n",
    "\n",
    "Print out for each level of taxonomy the table that compares across profilers and cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b14fdab8-b385-41e3-8fa5-53c5a03480a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kraken_overlap_data_dict = {'Kingdom':{}, 'Phylum':{}, 'Class':{}, 'Order':{}, 'Family':{}, 'Genus':{}, 'Species':{}}\n",
    "for level in kraken_overlap_data_dict.keys():\n",
    "    kraken_overlap_data_dict[level] = kraken_overlap[level]['Overlap']\n",
    "mph_overlap_data_dict = {'Kingdom':{}, 'Phylum':{}, 'Class':{}, 'Order':{}, 'Family':{}, 'Genus':{}, 'Species':{}}\n",
    "for level in mph_overlap_data_dict.keys():\n",
    "    mph_overlap_data_dict[level] = mph_overlap[level]['Overlap']\n",
    "ilo_overlap_data_dict = {'Kingdom':{}, 'Phylum':{}, 'Class':{}, 'Order':{}, 'Family':{}, 'Genus':{}, 'Species':{}}\n",
    "for level in ilo_overlap_data_dict.keys():\n",
    "    ilo_overlap_data_dict[level] = ilo_overlap[level]['Overlap']\n",
    "xu_overlap_data_dict = {'Kingdom':{}, 'Phylum':{}, 'Class':{}, 'Order':{}, 'Family':{}, 'Genus':{}, 'Species':{}}\n",
    "for level in xu_overlap_data_dict.keys():\n",
    "    xu_overlap_data_dict[level] = xu_overlap[level]['Overlap']\n",
    "\n",
    "all_overlap_cohort = taxa_overlap('ilo', 'han', ilo_overlap_data_dict, xu_overlap_data_dict, verbose=False)\n",
    "all_overlap_profiler = taxa_overlap('mph', 'kraken', mph_overlap_data_dict, kraken_overlap_data_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e10f7a40-93d0-48b9-82e6-2335bfe5920c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kingdom\n",
      "\n",
      "                  Reference DB  ILO  Xu et. al  Cohort Overlap\n",
      "Kraken2                      4    3          3               3\n",
      "MetaPhlAn4                   3    3          3               3\n",
      "Profiler Overlap             3    3          3               3\n",
      "\n",
      "\n",
      "Phylum\n",
      "\n",
      "                  Reference DB  ILO  Xu et. al  Cohort Overlap\n",
      "Kraken2                     90   20         25              20\n",
      "MetaPhlAn4                  93   12         12              12\n",
      "Profiler Overlap            61   11         11              11\n",
      "\n",
      "\n",
      "Class\n",
      "\n",
      "                  Reference DB  ILO  Xu et. al  Cohort Overlap\n",
      "Kraken2                    178   36         40              29\n",
      "MetaPhlAn4                 131   22         24              22\n",
      "Profiler Overlap           106   18         20              18\n",
      "\n",
      "\n",
      "Order\n",
      "\n",
      "                  Reference DB  ILO  Xu et. al  Cohort Overlap\n",
      "Kraken2                    342   58         73              48\n",
      "MetaPhlAn4                 279   38         45              37\n",
      "Profiler Overlap           226   34         41              33\n",
      "\n",
      "\n",
      "Family\n",
      "\n",
      "                  Reference DB  ILO  Xu et. al  Cohort Overlap\n",
      "Kraken2                    842  126        150             102\n",
      "MetaPhlAn4                 653   77         93              74\n",
      "Profiler Overlap           495   68         84              64\n",
      "\n",
      "\n",
      "Genus\n",
      "\n",
      "                  Reference DB  ILO  Xu et. al  Cohort Overlap\n",
      "Kraken2                   4457  372        436             298\n",
      "MetaPhlAn4                3490  289        325             248\n",
      "Profiler Overlap          1893  164        200             141\n",
      "\n",
      "\n",
      "Species\n",
      "\n",
      "                  Reference DB   ILO  Xu et. al  Cohort Overlap\n",
      "Kraken2                  23127  1044       1504             846\n",
      "MetaPhlAn4               20789   787        898             626\n",
      "Profiler Overlap          6292   335        422             281\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overlap_df_dict = {}\n",
    "for level in db_overlap.keys():\n",
    "    #create dataframe\n",
    "    df = pd.DataFrame(index=['Kraken2', 'MetaPhlAn4', 'Profiler Overlap'], columns= ['Reference DB', 'ILO', 'Xu et. al', 'Cohort Overlap'])\n",
    "    df['Reference DB'] = [(len(db_overlap[level]['Overlap']) + len(db_overlap[level]['kraken'])), (len(db_overlap[level]['Overlap']) + len(db_overlap[level]['mph'])),len(db_overlap[level]['Overlap'])] \n",
    "    df['ILO'] = [(len(ilo_overlap[level]['Overlap']) + len(ilo_overlap[level]['kraken'])), (len(ilo_overlap[level]['Overlap']) + len(ilo_overlap[level]['mph'])),len(ilo_overlap[level]['Overlap'])]\n",
    "    df['Xu et. al'] = [(len(xu_overlap[level]['Overlap']) + len(xu_overlap[level]['kraken'])), (len(xu_overlap[level]['Overlap']) + len(xu_overlap[level]['mph'])),len(xu_overlap[level]['Overlap'])]\n",
    "    df['Cohort Overlap'] = [len(kraken_overlap[level]['Overlap']), len(mph_overlap[level]['Overlap']), len(all_overlap_cohort[level]['Overlap'])]\n",
    "    overlap_df_dict[level] = df\n",
    "    print(level + '\\n')\n",
    "    print(df)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
